{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna version: 3.2.0\n",
      "Torch version: 2.0.0\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats={'png','retina'}\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from utils import calculate_descriptors\n",
    "from model import model_utils\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CycPeptMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'Fusion'\n",
    "# OPTIMIZE: Augmentation times\n",
    "REPLICA_NUM = 60\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = config['data']['seed']\n",
    "model_utils.set_seed(seed)\n",
    "\n",
    "# Import dataset, already removed duplicates\n",
    "# WARNING: conf matrix of atom model is huge\n",
    "set_list = ['Test', 'Caco2', 'MDCK', 'RRCK']\n",
    "dataset_test  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'Test')\n",
    "dataset_caco2 = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'Caco2')\n",
    "dataset_mdck  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'MDCK')\n",
    "dataset_rrck  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'RRCK')\n",
    "dataset_list = [dataset_test, dataset_caco2, dataset_mdck, dataset_rrck]\n",
    "\n",
    "# Determined hyperparameters\n",
    "best_trial = config['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(3):\n",
    "    # Load trained weights\n",
    "    model_path = f'weight/{MODEL_TYPE}/{MODEL_TYPE}-{REPLICA_NUM}_cv{cv}.cpt'\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model = model_utils.create_model(best_trial, DEVICE, config['model']['use_auxiliary'])\n",
    "    model_state = checkpoint['model_state_dict']\n",
    "    model.load_state_dict(model_state)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for set_name, dataset_now in zip(set_list, dataset_list):\n",
    "        dataloader_now = torch.utils.data.DataLoader(dataset_now, batch_size=256, shuffle=False)\n",
    "        ids, exps, preds = model_utils.predict_valid(DEVICE, model, dataloader_now, None, istrain=False,\n",
    "                                                     use_auxiliary=config['model']['use_auxiliary'], gamma_layer=config['model']['gamma_layer'], gamma_subout=config['model']['gamma_subout'])\n",
    "        now_pred = pd.DataFrame(preds, columns=['pred'])\n",
    "        now_pred['exp'] = exps\n",
    "        now_pred['ID'] = ids\n",
    "\n",
    "        # NOTE: Can save all predicted values of all replicas\n",
    "        # now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}_allrep.csv')\n",
    "\n",
    "        # Take the average of all replicas\n",
    "        now_pred = now_pred.groupby('ID').mean()\n",
    "        now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "for cv in range(3):\n",
    "    metrics = []\n",
    "    for set_name in set_list:\n",
    "        now_pred = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')\n",
    "        metrics.append([set_name] + list(model_utils.evaluate_model(now_pred['exp'].to_list(), now_pred['pred'].to_list(), round_num=5)))\n",
    "    metrics = pd.DataFrame(metrics, columns=['Set', 'MAE', 'RMSE', 'R', 'MSE', 'R2'])\n",
    "    metrics.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv{cv}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Fusion-60\n",
      " - Test:\n",
      "   - MAE: 0.355 ± 0.007, MSE: 0.253 ± 0.013, R: 0.883 ± 0.003, R2: 0.772 ± 0.011\n",
      " - Caco2:\n",
      "   - MAE: 1.148 ± 0.113, MSE: 1.66 ± 0.312, R: 0.209 ± 0.064, R2: -4.429 ± 1.022\n",
      " - MDCK:\n",
      "   - MAE: 0.821 ± 0.009, MSE: 0.911 ± 0.012, R: 0.57 ± 0.044, R2: -0.93 ± 0.025\n",
      " - RRCK:\n",
      "   - MAE: 0.678 ± 0.041, MSE: 0.652 ± 0.083, R: -0.181 ± 0.027, R2: -1.725 ± 0.346\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZE\n",
    "MODEL_TYPE = 'Fusion'\n",
    "REPLICA_NUM = 60\n",
    "set_list = ['Test', 'Caco2', 'MDCK', 'RRCK']\n",
    "\n",
    "metrics_cv0 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv0.csv').iloc[:, 1:]\n",
    "metrics_cv1 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv1.csv').iloc[:, 1:]\n",
    "metrics_cv2 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv2.csv').iloc[:, 1:]\n",
    "metrics = np.array([metrics_cv0, metrics_cv1, metrics_cv2])\n",
    "means = np.round(np.mean(metrics, axis=0), 3)\n",
    "stds = np.round(np.std(metrics, axis=0), 3)\n",
    "\n",
    "print(f'Model: {MODEL_TYPE}-{REPLICA_NUM}')\n",
    "for i in range(len(set_list)):\n",
    "    print(f' - {set_list[i]}:')\n",
    "    print(f'   - MAE: {means[i][0]} ± {stds[i][0]}, MSE: {means[i][3]} ± {stds[i][3]}, R: {means[i][2]} ± {stds[i][2]}, R2: {means[i][4]} ± {stds[i][4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/baselines.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "\n",
    "# Scaling permeabilities\n",
    "LOWER_LIMIT = config['data']['lower_limit']\n",
    "UPPER_LIMIT = config['data']['upper_limit']\n",
    "\n",
    "train_index_, valid_index_ = {}, {}\n",
    "for cv in range(3):\n",
    "    train_index_[cv] = np.load(f'data/eval_index/train_index_cv{cv}.npy')\n",
    "    valid_index_[cv] = np.load(f'data/eval_index/valid_index_cv{cv}.npy')\n",
    "test_index  = np.load(f'data/eval_index/Test_index.npy')\n",
    "caco2_index = np.load(f'data/eval_index/Caco2_index.npy')\n",
    "mdck_index  = np.load(f'data/eval_index/MDCK_index.npy')\n",
    "rrck_index  = np.load(f'data/eval_index/RRCK_index.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAMPA: 6941 -> 6889\n",
      "Caco2: 649 -> 378\n",
      "MDCK: 40 -> 17\n",
      "RRCK: 186 -> 53\n",
      "LogPexp < LOWER_LIMIT(-8) : 318\n",
      "LogPexp > UPPER_LIMIT(-4) : 1\n"
     ]
    }
   ],
   "source": [
    "# # Include duplicates (7451 peptides)\n",
    "# df = pd.read_csv('desc/peptide_2D_all.csv', low_memory=False)\n",
    "# df_ = {}\n",
    "# label_list = []\n",
    "# for assay in ['PAMPA', 'Caco2', 'MDCK', 'RRCK']:\n",
    "#     df_[assay] = df[~df[assay].isna()].reset_index(drop=True)\n",
    "#     print(f'{assay}: {len(df_[assay])}', end=\" -> \")\n",
    "\n",
    "#     # Remove peptides that are included in PAMPA\n",
    "#     if assay != 'PAMPA':\n",
    "#         tmp = []\n",
    "#         for i in range(len(df_[assay])):\n",
    "#             if df_[assay]['structurally_unique_ID'].to_list()[i] not in df_['PAMPA']['structurally_unique_ID'].to_list():\n",
    "#                 tmp.append(i)\n",
    "#         df_[assay] = df_[assay].iloc[tmp]\n",
    "#         # print(f' {len(df_[assay])}', end=\"\")\n",
    "\n",
    "#     # IMPORTANT: Remove duplicates, using permeability from the latest publication\n",
    "#     dup = df_[assay].duplicated('SMILES', keep='last')\n",
    "#     df_[assay] = df_[assay][~dup]\n",
    "#     df_[assay] = df_[assay].reset_index(drop=True)\n",
    "#     print(f'{len(df_[assay])}')\n",
    "#     label_list.append(df_[assay][assay].to_list())\n",
    "\n",
    "# # 7337 peptides\n",
    "# df = pd.concat([df_['PAMPA'], df_['Caco2'], df_['MDCK'], df_['RRCK']], axis=0).reset_index(drop=True)\n",
    "# label_list = sum(label_list, [])\n",
    "\n",
    "# # Scaling permeabilities\n",
    "# print(f\"LogPexp < LOWER_LIMIT({LOWER_LIMIT}) : {len([_ for _ in label_list if _ < LOWER_LIMIT])}\")\n",
    "# print(f\"LogPexp > UPPER_LIMIT({UPPER_LIMIT}) : {len([_ for _ in label_list if _ > UPPER_LIMIT])}\")\n",
    "# label_list = np.clip(label_list, LOWER_LIMIT, UPPER_LIMIT)\n",
    "# df['y'] = label_list\n",
    "\n",
    "# # Information + 2D descriptors\n",
    "# df_2D = df[['ID','Set','Year','ID_org','structurally_unique_ID','SMILES','HELM','Monomer_number','Monomer_number_in_main_chain','shape',\\\n",
    "#             'Objective_variable','PAMPA','Caco2','MDCK','RRCK','y'] + config['SVM']['desc_2D']].copy()\n",
    "\n",
    "# # For SVM model, only use 3D descriptors calculated from single conformer\n",
    "# df_3D = pd.read_csv('desc/peptide_3D_v1.csv', low_memory=False)\n",
    "# df_3D = df_3D[config['SVM']['desc_3D']].iloc[[30*_ for _ in range(7337)]].reset_index(drop=True)\n",
    "\n",
    "# df = pd.concat([df_2D, df_3D], axis=1)\n",
    "# df.to_csv('desc/peptide_used.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM & RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7337/7337 [00:06<00:00, 1215.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('desc/peptide_used.csv', low_memory=False)\n",
    "y = df['y'].to_numpy()\n",
    "\n",
    "# Standardization by Z-score\n",
    "desc = df[config['SVM']['desc_2D'] + config['SVM']['desc_3D']].copy()\n",
    "desc = desc.apply(zscore)\n",
    "\n",
    "# Morgan fingerprint\n",
    "fps = calculate_descriptors.calc_fingerprint(df['SMILES'].to_list(), radius=2, bit_num=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['RF', 'SVM-2D', 'SVM-2D3D']:\n",
    "    if model_name == 'RF':\n",
    "        model = RandomForestRegressor(random_state=233, n_estimators=config['RF']['n_estimators'], max_depth=config['RF']['max_depth'], n_jobs=12)\n",
    "        data = fps\n",
    "    elif model_name == 'SVM-2D':\n",
    "        model = svm.SVR(C=config['SVM']['C-2D'], gamma=config['SVM']['gamma-2D'])\n",
    "        data = desc[config['SVM']['desc_2D']].values\n",
    "    elif model_name == 'SVM-2D3D':\n",
    "        model = svm.SVR(C=config['SVM']['C-2D3D'], gamma=config['SVM']['gamma-2D3D'])\n",
    "        data = desc.values\n",
    "\n",
    "    for cv in range(3):\n",
    "        metrics = []\n",
    "\n",
    "        model.fit(data[train_index_[cv]], y[train_index_[cv]])\n",
    "\n",
    "        for set_name, index_now in zip(['Valid', 'Test', 'Caco2', 'MDCK', 'RRCK'], \\\n",
    "                                       [valid_index_[cv], test_index, caco2_index, mdck_index, rrck_index]):\n",
    "            now_pred = pd.DataFrame([df.iloc[index_now]['ID']], index=['ID']).T\n",
    "            exp  = y[index_now]\n",
    "            pred = model.predict(data[index_now])\n",
    "            now_pred['exp']  = exp\n",
    "            now_pred['pred'] = pred\n",
    "            # Can save predicted values\n",
    "            # now_pred.to_csv(f'predicted/{model_name}/{set_name}_cv{cv}.csv')\n",
    "\n",
    "            metrics.append([set_name] + list(model_utils.evaluate_model(exp, pred)))\n",
    "\n",
    "        metrics = pd.DataFrame(metrics, columns=['Set', 'MAE', 'RMSE', 'R', 'MSE', 'R2'])\n",
    "        metrics.to_csv(f'predicted/{model_name}/metrics_cv{cv}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RF\n",
      " - Valid:\n",
      "   - MAE: 0.41 ± 0.01, MSE: 0.328 ± 0.025, R: 0.716 ± 0.022, R2: 0.511 ± 0.033\n",
      " - Test:\n",
      "   - MAE: 0.485 ± 0.003, MSE: 0.38 ± 0.004, R: 0.815 ± 0.003, R2: 0.657 ± 0.003\n",
      " - Caco2:\n",
      "   - MAE: 1.124 ± 0.006, MSE: 1.562 ± 0.013, R: 0.181 ± 0.002, R2: -4.125 ± 0.043\n",
      " - MDCK:\n",
      "   - MAE: 0.913 ± 0.016, MSE: 1.094 ± 0.039, R: 0.283 ± 0.021, R2: -1.318 ± 0.083\n",
      " - RRCK:\n",
      "   - MAE: 0.683 ± 0.026, MSE: 0.655 ± 0.042, R: -0.044 ± 0.045, R2: -1.259 ± 0.146\n",
      "\n",
      "Model: SVM-2D\n",
      " - Valid:\n",
      "   - MAE: 0.401 ± 0.012, MSE: 0.351 ± 0.02, R: 0.7 ± 0.009, R2: 0.477 ± 0.011\n",
      " - Test:\n",
      "   - MAE: 0.488 ± 0.005, MSE: 0.449 ± 0.014, R: 0.781 ± 0.007, R2: 0.595 ± 0.012\n",
      " - Caco2:\n",
      "   - MAE: 0.784 ± 0.007, MSE: 0.916 ± 0.007, R: 0.279 ± 0.016, R2: -2.005 ± 0.023\n",
      " - MDCK:\n",
      "   - MAE: 0.706 ± 0.022, MSE: 0.774 ± 0.044, R: 0.377 ± 0.072, R2: -0.641 ± 0.094\n",
      " - RRCK:\n",
      "   - MAE: 0.662 ± 0.007, MSE: 0.612 ± 0.017, R: 0.245 ± 0.006, R2: -1.111 ± 0.06\n",
      "\n",
      "Model: SVM-2D3D\n",
      " - Valid:\n",
      "   - MAE: 0.392 ± 0.007, MSE: 0.336 ± 0.015, R: 0.713 ± 0.021, R2: 0.498 ± 0.029\n",
      " - Test:\n",
      "   - MAE: 0.418 ± 0.001, MSE: 0.345 ± 0.002, R: 0.834 ± 0.001, R2: 0.689 ± 0.002\n",
      " - Caco2:\n",
      "   - MAE: 0.766 ± 0.007, MSE: 0.894 ± 0.018, R: 0.29 ± 0.004, R2: -1.935 ± 0.062\n",
      " - MDCK:\n",
      "   - MAE: 0.778 ± 0.005, MSE: 0.814 ± 0.012, R: 0.618 ± 0.011, R2: -0.724 ± 0.025\n",
      " - RRCK:\n",
      "   - MAE: 0.598 ± 0.005, MSE: 0.603 ± 0.013, R: 0.291 ± 0.016, R2: -1.08 ± 0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def summrize_metrics(model_name):\n",
    "    metrics_cv0 = pd.read_csv(f'predicted/{model_name}/metrics_cv0.csv').iloc[:, 1:]\n",
    "    metrics_cv1 = pd.read_csv(f'predicted/{model_name}/metrics_cv1.csv').iloc[:, 1:]\n",
    "    metrics_cv2 = pd.read_csv(f'predicted/{model_name}/metrics_cv2.csv').iloc[:, 1:]\n",
    "    metrics = np.array([metrics_cv0, metrics_cv1, metrics_cv2])\n",
    "    means = np.round(np.mean(metrics, axis=0), 3)\n",
    "    stds = np.round(np.std(metrics, axis=0), 3)\n",
    "    return means, stds\n",
    "\n",
    "\n",
    "set_list = ['Valid', 'Test', 'Caco2', 'MDCK', 'RRCK']\n",
    "for model_name in ['RF', 'SVM-2D', 'SVM-2D3D']:\n",
    "    print(f'Model: {model_name}')\n",
    "    means, stds = summrize_metrics(model_name)\n",
    "    for i in range(len(set_list)):\n",
    "        print(f' - {set_list[i]}:')\n",
    "        print(f'   - MAE: {means[i][0]} ± {stds[i][0]}, MSE: {means[i][3]} ± {stds[i][3]}, R: {means[i][2]} ± {stds[i][2]}, R2: {means[i][4]} ± {stds[i][4]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Other DL-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
