{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna version: 3.2.0\n",
      "Torch version: 2.0.0\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats={'png','retina'}\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "\"\"\"\"\"\"\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchinfo import summary\n",
    "\"\"\"\"\"\"\n",
    "from model import model_utils\n",
    "\"\"\"\"\"\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Optuna version: {optuna.__version__}')\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(model_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling permeabilities\n",
    "LOWER_LIMIT = -8\n",
    "UPPER_LIMIT = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CycPeptMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZE\n",
    "MODEL_TYPE = 'Fusion'\n",
    "# Augmentation times\n",
    "REPLICA_NUM = 60\n",
    "\n",
    "\n",
    "# Use auxiliary loss for training\n",
    "USE_AUXILIARY = True\n",
    "# Weight of auxiliary loss\n",
    "gamma_layer  = 0.05\n",
    "gamma_subout = 0.10\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 2024\n",
    "model_utils.set_seed(seed)\n",
    "\n",
    "# import dataset\n",
    "# WARNING: conf matrix of atom model is huge\n",
    "set_list = ['Test', 'Caco2', 'MDCK', 'RRCK']\n",
    "dataset_test  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'Test')\n",
    "dataset_caco2 = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'Caco2')\n",
    "dataset_mdck  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'MDCK')\n",
    "dataset_rrck  = model_utils.load_dataset(MODEL_TYPE, REPLICA_NUM, 'RRCK')\n",
    "dataset_list = [dataset_test, dataset_caco2, dataset_mdck, dataset_rrck]\n",
    "\n",
    "# Determined hyperparameters\n",
    "best_trial = config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict permeabilities\n",
    "for cv in range(3):\n",
    "    # Load trained weights\n",
    "    model_path = f'weight/{MODEL_TYPE}/{MODEL_TYPE}-{REPLICA_NUM}_cv{cv}.cpt'\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model = model_utils.create_model(best_trial, DEVICE, USE_AUXILIARY)\n",
    "    model_state = checkpoint['model_state_dict']\n",
    "    model.load_state_dict(model_state)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for set_name, dataset_now in zip(set_list, dataset_list):\n",
    "        dataloader_now = torch.utils.data.DataLoader(dataset_now, batch_size=256, shuffle=False)\n",
    "        ids, exps, preds = model_utils.predict_valid(DEVICE, model, dataloader_now, None, istrain=False,\n",
    "                                                     use_auxiliary=USE_AUXILIARY, gamma_layer=gamma_layer, gamma_subout=gamma_subout)\n",
    "        now_pred = pd.DataFrame(preds, columns=['pred'])\n",
    "        now_pred['exp'] = exps\n",
    "        now_pred['ID'] = ids\n",
    "\n",
    "        # NOTE: Can save all predicted values of all replicas\n",
    "        # now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}_allrep.csv')\n",
    "\n",
    "        # Take the average of all replicas\n",
    "        now_pred = now_pred.groupby('ID').mean()\n",
    "        now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "for cv in range(3):\n",
    "    metrics = []\n",
    "    for set_name in set_list:\n",
    "        now_pred = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')\n",
    "        metrics.append([set_name] + list(model_utils.evaluate_model(now_pred['exp'].to_list(), now_pred['pred'].to_list(), round_num=5)))\n",
    "    metrics = pd.DataFrame(metrics, columns=['Set', 'MAE', 'RMSE', 'R', 'MSE', 'R2'])\n",
    "    metrics.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv{cv}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Fusion-60\n",
      "Test:\n",
      "MAE: 0.355 ± 0.007, MSE: 0.253 ± 0.013, R: 0.883 ± 0.003, R2: 0.772 ± 0.011\n",
      "Caco2:\n",
      "MAE: 1.148 ± 0.113, MSE: 1.66 ± 0.312, R: 0.209 ± 0.064, R2: -4.429 ± 1.022\n",
      "MDCK:\n",
      "MAE: 0.821 ± 0.009, MSE: 0.911 ± 0.012, R: 0.57 ± 0.044, R2: -0.93 ± 0.025\n",
      "RRCK:\n",
      "MAE: 0.678 ± 0.041, MSE: 0.652 ± 0.083, R: -0.181 ± 0.027, R2: -1.725 ± 0.346\n"
     ]
    }
   ],
   "source": [
    "# # OPTIMIZE\n",
    "# MODEL_TYPE = 'Fusion'\n",
    "# REPLICA_NUM = 60\n",
    "\n",
    "metrics_cv0 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv0.csv').iloc[:, 1:]\n",
    "metrics_cv1 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv1.csv').iloc[:, 1:]\n",
    "metrics_cv2 = pd.read_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/metrics_cv2.csv').iloc[:, 1:]\n",
    "metrics = np.array([metrics_cv0, metrics_cv1, metrics_cv2])\n",
    "means = np.round(np.mean(metrics, axis=0), 3)\n",
    "stds = np.round(np.std(metrics, axis=0), 3)\n",
    "\n",
    "print(f'Model: {MODEL_TYPE}-{REPLICA_NUM}')\n",
    "for i in range(len(set_list)):\n",
    "    print(f'{set_list[i]}:')\n",
    "    print(f'MAE: {means[i][0]} ± {stds[i][0]}, MSE: {means[i][3]} ± {stds[i][3]}, R: {means[i][2]} ± {stds[i][2]}, R2: {means[i][4]} ± {stds[i][4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
