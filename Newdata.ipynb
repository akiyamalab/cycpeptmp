{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.0.0\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "from utils import utils_function\n",
    "from utils import calculate_descriptors\n",
    "from utils import generate_conformation\n",
    "from utils import generate_atom_input\n",
    "from utils import generate_monomer_input\n",
    "from utils import generate_peptide_input\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import model_utils\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cyclic peptide drugs, without experimentally determined permeability.\n",
    "# Anidulafungin, Pasireotide\n",
    "new_data = pd.read_csv('data/new_data/new_data.csv')\n",
    "\n",
    "# Check duplicates\n",
    "old_data = pd.read_csv('data/CycPeptMPDB_Peptide_All.csv', low_memory=False)\n",
    "for i in range(len(new_data)):\n",
    "    if utils_function.canonicalize_smiles(new_data.iloc[i]['SMILES']) in old_data['SMILES'].to_list():\n",
    "        print(f'Your peptide: {i} ({new_data.iloc[i][\"ID_org\"]}) is already in the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Divide peptide into monomers (substructures)\n",
    "+ Divides __peptide bond__ and __ester bond__ in the __main chain__ and splits peptide into monomers.\n",
    "+ The cleaved amide group or O atom of the amide-to-ester substitution was methylated (addition of CH3), and the carboxyl group was converted to an aldehyde (addition of H).\n",
    "+ __Disulfide bond__ is not included in CycPeptMPDB data, but it may be better to consider it as a division target.\n",
    "+ __Bonds in side-chain__ are not subject to division to fully represent the side-chain properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique monomers\n",
    "utils_function.get_unique_monomer(new_data, 'data/new_data/unique_monomer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate different peptide SMILES representations by SMILES enumeration as atom-level data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.enumerate_smiles(new_data, config, 'data/new_data/enum_smiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate 3D conformations for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [03:25<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('sdf/new_data/')\n",
    "\n",
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "\n",
    "# WARNING: If there is too much data, you can manually split it into multiple files for parallel computation.\n",
    "# For example:\n",
    "# sub_file_num = 10\n",
    "# sub_file_len = len(df_enu) // sub_file_num\n",
    "# for i in range(sub_file_num):\n",
    "#     df_enu.iloc[i*sub_file_len:(i+1)*sub_file_len].to_csv(f'sdf/new_data/peptide_{i}.csv', index=False)\n",
    "\n",
    "generate_conformation.generate_peptide_conformation(config, df_enu, 'sdf/new_data/peptide.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:36<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "df_monomer = pd.read_csv('data/new_data/unique_monomer.csv')\n",
    "generate_conformation.generate_monomer_conformation(config, df_monomer, 'sdf/new_data/monomer.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate 2D and 3D descriptors for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. RDKit (208 types 2D descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_rdkit_descriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_rdkit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 37.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_rdkit_descriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_rdkit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Mordred (1275 types 2D descriptors + 51 types 3D descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:32<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/peptide_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:32<00:00, 20.02it/s] \n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/monomer.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/monomer_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. MOE (206 types 2D descriptors + 117 types 3D descriptors)\n",
    "+ CycPeptMP used the commercial software __MOE__ to calculate some of the descriptors.\n",
    "+ In particular, many of the selected 3D descriptors were computed by MOE.\n",
    "+ Please manualy calculate these descriptors. I showed __utils/MOE_3D_descriptors.sh__ as an example.\n",
    "+ For 2D descriptors:\n",
    "    + Please wash SMILES and use washed mols for calculation.\n",
    "        + for GUI: Molecule -> Wash -> Protonation: Dominant\n",
    "+ For 3D descriptors:\n",
    "    + First, please calculate the charge for the RDKit conformations.\n",
    "        + for GUI: Compute -> Molecule -> Partial Charges\n",
    "    + 21 MOPAC descriptors of the 3D descriptors were not computed due to computational cost (AM_x, MNDO_, PM3_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Concatenation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_descriptors.merge_descriptors(config, 'desc/new_data/', 'data/new_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate input for three sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'model/input/new_data/'\n",
    "set_name = 'new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Atom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 701.12it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 311.35it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 476.95it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 448.57it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 646.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "\n",
    "generate_atom_input.generate_atom_input(config, new_data, df_enu, mols, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mono_2D = pd.read_csv('desc/new_data/monomer_2D.csv')\n",
    "df_mono_3D = pd.read_csv('desc/new_data/monomer_3D.csv')\n",
    "\n",
    "generate_monomer_input.generate_monomer_input(config, new_data, df_mono_2D, df_mono_3D, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Peptide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2007.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1003.30it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pep_2D = pd.read_csv('desc/new_data/peptide_2D.csv')\n",
    "df_pep_3D = pd.read_csv('desc/new_data/peptide_3D.csv')\n",
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "\n",
    "generate_peptide_input.generate_peptide_input(config, new_data, df_enu, df_pep_2D, df_pep_3D, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 30])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([16])\n",
      "torch.Size([2048])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE = 'Fusion'\n",
    "# OPTIMIZE: Augmentation times\n",
    "REPLICA_NUM = 60\n",
    "\n",
    "# Import input\n",
    "set_name = 'new'\n",
    "dataset_new = model_utils.load_dataset('model/input/new_data/', MODEL_TYPE, REPLICA_NUM, set_name)\n",
    "\n",
    "for _ in dataset_new[0]:\n",
    "    print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = config['data']['seed']\n",
    "model_utils.set_seed(seed)\n",
    "\n",
    "# Determined hyperparameters\n",
    "best_trial = config['model']\n",
    "\n",
    "for cv in range(3):\n",
    "    # Load trained weights\n",
    "    model_path = f'weight/{MODEL_TYPE}/{MODEL_TYPE}-{REPLICA_NUM}_cv{cv}.cpt'\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model = model_utils.create_model(best_trial, DEVICE, config['model']['use_auxiliary'])\n",
    "    model_state = checkpoint['model_state_dict']\n",
    "    model.load_state_dict(model_state)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # OPTIMIZE: Batch size\n",
    "    batch_size = len(dataset_new)\n",
    "    dataloader_now = torch.utils.data.DataLoader(dataset_new, batch_size=batch_size, shuffle=False)\n",
    "    ids, exps, preds = model_utils.predict_valid(DEVICE, model, dataloader_now, None, istrain=False,\n",
    "                                                 use_auxiliary=config['model']['use_auxiliary'], gamma_layer=config['model']['gamma_layer'], gamma_subout=config['model']['gamma_subout'])\n",
    "    now_pred = pd.DataFrame(preds, columns=['pred'])\n",
    "    now_pred['exp'] = exps\n",
    "    now_pred['ID'] = ids\n",
    "\n",
    "    # NOTE: Can save all predicted values of all replicas\n",
    "    # now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}_allrep.csv')\n",
    "\n",
    "    # Take the average of all replicas\n",
    "    now_pred = now_pred.groupby('ID').mean()\n",
    "    now_pred.to_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.788538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.024245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID      pred\n",
       "0  1.0 -6.788538\n",
       "1  2.0 -7.024245"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cv0 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv0.csv')\n",
    "pred_cv1 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv1.csv')\n",
    "pred_cv2 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv2.csv')\n",
    "\n",
    "pred_mean = (pred_cv0 + pred_cv1 + pred_cv2) / 3\n",
    "pred_mean[['ID', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
