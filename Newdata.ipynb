{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "from utils import utils_function\n",
    "from utils import calculate_descriptors\n",
    "from utils import generate_conformation\n",
    "from utils import generate_atom_input\n",
    "from utils import generate_monomer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cyclic peptide drugs, without experimentally determined permeability.\n",
    "# Anidulafungin, Pasireotide\n",
    "new_data = pd.read_csv('data/new_data/new_data.csv')\n",
    "\n",
    "# Check duplicates\n",
    "old_data = pd.read_csv('data/CycPeptMPDB_Peptide_All.csv', low_memory=False)\n",
    "for i in range(len(new_data)):\n",
    "    if utils_function.canonicalize_smiles(new_data.iloc[i]['SMILES']) in old_data['SMILES'].to_list():\n",
    "        print(f'Your peptide: {i} ({new_data.iloc[i][\"ID_org\"]}) is already in the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Divide peptide into monomers (substructures)\n",
    "+ Divides __peptide bond__ and __ester bond__ in the __main chain__ and splits peptide into monomers.\n",
    "+ The cleaved amide group or O atom of the amide-to-ester substitution was methylated (addition of CH3), and the carboxyl group was converted to an aldehyde (addition of H).\n",
    "+ __Disulfide bond__ is not included in CycPeptMPDB data, but it may be better to consider it as a division target.\n",
    "+ __Bonds in side-chain__ are not subject to division to fully represent the side-chain properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique monomers\n",
    "utils_function.get_unique_monomer(new_data, 'data/new_data/unique_monomer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate different peptide SMILES representations by SMILES enumeration as atom-level data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.enumerate_smiles(new_data, config, 'data/new_data/enum_smiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate 3D conformations for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [03:25<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('sdf/new_data/')\n",
    "\n",
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "\n",
    "# WARNING: If there is too much data, you can manually split it into multiple files for parallel computation.\n",
    "# For example:\n",
    "# sub_file_num = 10\n",
    "# sub_file_len = len(df_enu) // sub_file_num\n",
    "# for i in range(sub_file_num):\n",
    "#     df_enu.iloc[i*sub_file_len:(i+1)*sub_file_len].to_csv(f'sdf/new_data/peptide_{i}.csv', index=False)\n",
    "\n",
    "generate_conformation.generate_peptide_conformation(config, df_enu, 'sdf/new_data/peptide.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:36<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "df_monomer = pd.read_csv('data/new_data/unique_monomer.csv')\n",
    "generate_conformation.generate_monomer_conformation(config, df_monomer, 'sdf/new_data/monomer.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate 2D and 3D descriptors for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. RDKit (208 types 2D descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_rdkit_descriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_rdkit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 37.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_rdkit_descriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_rdkit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Mordred (1275 types 2D descriptors + 51 types 3D descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:32<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/peptide_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:32<00:00, 20.02it/s] \n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/monomer.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/monomer_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. MOE (206 types 2D descriptors + 117 types 3D descriptors)\n",
    "+ CycPeptMP used the commercial software __MOE__ to calculate some of the descriptors.\n",
    "+ In particular, many of the selected 3D descriptors were computed by MOE.\n",
    "+ Please manualy calculate these descriptors. I showed __utils/MOE_3D_descriptors.sh__ as an example.\n",
    "+ For 2D descriptors:\n",
    "    + Please wash SMILES and use washed mols for calculation.\n",
    "        + for GUI: Molecule -> Wash -> Protonation: Dominant\n",
    "+ For 3D descriptors:\n",
    "    + First, please calculate the charge for the RDKit conformations.\n",
    "        + for GUI: Compute -> Molecule -> Partial Charges\n",
    "    + 21 MOPAC descriptors of the 3D descriptors were not computed due to computational cost (AM_x, MNDO_, PM3_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Concatenation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_descriptors.merge_descriptors(config, 'desc/new_data/', 'data/new_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate input for three sub-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Atom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 634.00it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 280.58it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 427.77it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 435.62it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 638.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "\n",
    "# Peptide information\n",
    "id = df_enu['ID'].to_numpy()\n",
    "smiles = df_enu['SMILES'].to_numpy()\n",
    "y = new_data['permeability'].to_numpy()\n",
    "y = np.clip(y, config['data']['lower_limit'], config['data']['upper_limit'])\n",
    "\n",
    "# Atoms mask\n",
    "atoms_mask = generate_atom_input.get_atoms_mask(mols, config['data']['max_atommun'])\n",
    "# Atoms features (Node)\n",
    "atoms_features = generate_atom_input.calculate_atoms_features(mols, config['data']['max_atommun'], config['data']['atom_pad_val'])\n",
    "# Bonds type (Bond)\n",
    "bond = generate_atom_input.calculate_bond_type_matrix(mols, config['data']['max_atommun'])\n",
    "# Graph distance matrix (Graph)\n",
    "graph = generate_atom_input.calculate_graph_distance_matrix(mols, config['data']['max_atommun'], config['data']['atom_pad_val'])\n",
    "# 3D distance matrix (Conf)\n",
    "conf = generate_atom_input.calculate_conf_distance_matrix(mols, config['data']['max_atommun'], config['data']['atom_pad_val'])\n",
    "\n",
    "np.savez_compressed(f\"model/input/new_data/Trans/{config['augmentation']['replica_num']}/node_{config['augmentation']['replica_num']}_new.npz\",\n",
    "                    id=id,\n",
    "                    smiles=smiles,\n",
    "                    y=y,\n",
    "                    atoms_mask=atoms_mask,\n",
    "                    atoms_features=atoms_features)\n",
    "np.savez_compressed(f\"model/input/new_data/Trans/{config['augmentation']['replica_num']}/bond_{config['augmentation']['replica_num']}_new.npz\", bond=bond)\n",
    "np.savez_compressed(f\"model/input/new_data/Trans/{config['augmentation']['replica_num']}/graph_{config['augmentation']['replica_num']}_new.npz\", graph=graph)\n",
    "np.savez_compressed(f\"model/input/new_data/Trans/{config['augmentation']['replica_num']}/conf_{config['augmentation']['replica_num']}_new.npz\", conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: You can also generate input data for different augmentation times\n",
    "# # For example:\n",
    "# total_list = list(range(0, len(df_enu)))\n",
    "# for replica_num in [1, 5, 10, 20, 30, 40, 50]:\n",
    "#     # IMPORTANT\n",
    "#     select_list = [total_list[i:i+replica_num] for i in range(0, len(total_list), 60)]\n",
    "#     select_list = sum(select_list, [])\n",
    "#     np.savez_compressed(f\"model/input/new_data/Trans/{replica_num}/node_{replica_num}_new.npz\"\n",
    "#                         id=id[select_list],\n",
    "#                         smiles=smiles[select_list],\n",
    "#                         y=y[select_list],\n",
    "#                         atoms_mask=atoms_mask[select_list],\n",
    "#                         atoms_features=atoms_features[select_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.read_csv('data/new_data/new_data.csv')\n",
    "df_mono_2D = pd.read_csv('desc/new_data/monomer_2D.csv')\n",
    "df_mono_3D = pd.read_csv('desc/new_data/monomer_3D.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Monomer ID sequence\n",
    "sequence_number = [[SMILES_to_ID[j] if j in SMILES_to_ID else config['data']['mono_pad_id'] for j in i] for i in sequence]\n",
    "\n",
    "# Align the part with information in the middle\n",
    "sequence_number = [[config['data']['mono_pad_id']]*int(np.trunc((config['data']['mono_max_len']-now_len)/2)) + \\\n",
    "                    now_seq[:now_len] + \\\n",
    "                    [config['data']['mono_pad_id']]*int(np.ceil((config['data']['mono_max_len']-now_len)/2)) \\\n",
    "                    for now_seq, now_len in zip(sequence_number, np.sum(~pd.isna(sequence), axis=1))]\n",
    "sequence_number = np.array(sequence_number)\n",
    "\n",
    "use_descriptors = config['descriptor']['desc_2D'] + config['descriptor']['desc_3D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_sequence_number, aug_sequence_length, aug_peptide_ID = generate_monomer_input.perform_augmentation(sequence_number, config['data']['mono_max_len'], config['data']['mono_pad_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mono = pd.concat([df_mono_2D.iloc[sum([[_]*config['augmentation']['replica_num'] for _ in range(len(df_mono_2D))], [])].reset_index(drop=True), df_mono_3D], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'VSA_EState9_mordred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VSA_EState9_mordred'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_mono_2D\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVSA_EState9_mordred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VSA_EState9_mordred'"
     ]
    }
   ],
   "source": [
    "df_mono_2D['VSA_EState9_mordred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['VSA_EState9_mordred'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_preprocessing \u001b[38;5;241m=\u001b[39m \u001b[43mdf_mono\u001b[49m\u001b[43m[\u001b[49m\u001b[43muse_descriptors\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3766\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3765\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3766\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3768\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['VSA_EState9_mordred'] not in index\""
     ]
    }
   ],
   "source": [
    "data_preprocessing = df_mono[use_descriptors].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGED 2023/10/17\n",
    "\n",
    "# !\n",
    "# df_mono_3D = pd.concat([df_substructure_3D, df_substructure_3D_v2], axis=0).sort_values('Energy').sort_values('ID').reset_index(drop=True)\n",
    "\n",
    "data_preprocessing = df_mono[use_descriptors].copy()\n",
    "\n",
    "# CHANGED\n",
    "# zscore for all 60 replicas\n",
    "print('mean:')\n",
    "print(data_preprocessing.mean(axis=0))\n",
    "print('std:')\n",
    "print(data_preprocessing.std(axis=0))\n",
    "\n",
    "data_preprocessing = data_preprocessing.apply(zscore)\n",
    "\n",
    "\n",
    "# 各replicaにindexを付与\n",
    "data_preprocessing['replica_index'] = sum([[_ for _ in range(config['augmentation']['replica_num'])]*387], [])\n",
    "data_preprocessing.index = df_mono_3D['ID']\n",
    "\n",
    "# aug_tableを選択\n",
    "df_feature_map = pd.DataFrame(aug_ID, columns=['aug_ID'])\n",
    "df_feature_map['aug_table'] = aug_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.calculate_descriptors' from '/Users/yoshio/Desktop/cycpeptmp/utils/calculate_descriptors.py'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(calculate_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peptide = pd.read_csv(data_args['org_peptide_path'], low_memory=False)\n",
    "df_monomer = pd.read_csv(data_args['org_monomer_path'], low_memory=False)\n",
    "\n",
    "smiles = df_peptide['SMILES'].tolist()\n",
    "shape = df_peptide['Molecule_Shape'].to_list()\n",
    "helm = df_peptide['HELM'].to_list()\n",
    "symbol_to_smiles = dict(zip(df_monomer['Symbol'], df_monomer['capped_SMILES']))\n",
    "symbol_to_cxsmiles = dict(zip(df_monomer['Symbol'], df_monomer['CXSMILES']))\n",
    "R3_dict = dict(zip(df_monomer['Symbol'], df_monomer['R3']))\n",
    "smiles_to_symbol = dict(zip(df_monomer['capped_SMILES'], df_monomer['Symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substructure_list, substructure_num = [], []\n",
    "\n",
    "for i in range(len(df_peptide)):\n",
    "\n",
    "    now_substructure = []\n",
    "    now_seq = helm[i].split('$')[0].split('{')[1].replace('}', '').replace('[', '').replace(']', '').split('.')\n",
    "\n",
    "    if shape[i] == 'Circle':\n",
    "        now_substructure = [symbol_to_smiles[_] for _ in now_seq]\n",
    "    elif shape[i] == 'Lariat':\n",
    "        # Lariat peptides, do not divide bonds of side chain\n",
    "        atts = helm[i].split('$')[1].split(',')[2].split('-')\n",
    "        atts_num = [int(_.split(':')[0]) for _ in atts]\n",
    "        atts_R = [_.split(':')[1] for _ in atts]\n",
    "\n",
    "        # HELM example of this case: PEPTIDE48{A.A.L.[meV].L.F.F.P.I.T.G.D.[-pip]}$PEPTIDE48,PEPTIDE48,1:R1-12:R3$$$\n",
    "        if atts_num[0] == 1:\n",
    "            # NOTE: This case were all R1-R3\n",
    "            # if atts_R[0] != 'R1':\n",
    "            #     print(f'{i}, 0, {atts_R[0]}')\n",
    "            # elif atts_R[1] != 'R3':\n",
    "            #     print(f'{i}, 1, {atts_R[1]}')\n",
    "\n",
    "            now_substructure = [symbol_to_smiles[_] for _ in now_seq[:atts_num[1]-1]]\n",
    "            # monomers to combine\n",
    "            cxsmiles = [symbol_to_cxsmiles[_] for _ in now_seq[atts_num[1]-1:]]\n",
    "            # NOTE: 第一个cap两处(R1, R3), side chain不cap\n",
    "            tmp = cxsmiles[0].split(' |')[0]\n",
    "            for _ in re.findall('_R\\d', cxsmiles[0]):\n",
    "                if _ == '_R1':\n",
    "                    tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                elif _ == '_R2':\n",
    "                    tmp = tmp.replace('[*]', '[2C]', 1)\n",
    "                elif _ == '_R3':\n",
    "                    if R3_dict[now_seq[atts_num[1]-1]] == 'H':\n",
    "                        tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                    elif R3_dict[now_seq[atts_num[1]-1]] == 'OH':\n",
    "                        tmp = tmp.replace('[*]', '[H]', 1)\n",
    "            cxsmiles[0] = tmp\n",
    "\n",
    "            combined = utils_function.combine_cxsmiles(cxsmiles, now_seq[atts_num[1]-1:], R3_dict)\n",
    "            now_substructure.append(combined)\n",
    "\n",
    "        # HELM example of this case: PEPTIDE959{[Mono22-].G.T.[Mono23].[Mono24].[dLeu(3R-OH)].[dSer(Me)].G.A.[meT].[dTyr(bR-OMe)].[Mono25]}$PEPTIDE959,PEPTIDE959,6:R3-12:R2$$$\n",
    "        else:\n",
    "            # NOTE: This case were all R3-R2\n",
    "            # if atts_R[0] != 'R3':\n",
    "            #     print(f'{i}, 0, {atts_R[0]}')\n",
    "            # elif atts_R[1] != 'R2':\n",
    "            #     print(f'{i}, 1, {atts_R[1]}')\n",
    "            cxsmiles = [symbol_to_cxsmiles[_] for _ in now_seq[:atts_num[0]]]\n",
    "            # NOTE: 最后一个cap两处(R2, R3), side chain不cap\n",
    "            tmp = cxsmiles[-1].split(' |')[0]\n",
    "            for _ in re.findall('_R\\d', cxsmiles[-1]):\n",
    "                if _ == '_R1':\n",
    "                    tmp = tmp.replace('[*]', '[1C]', 1)\n",
    "                elif _ == '_R2':\n",
    "                    tmp = tmp.replace('[*]', '[H]', 1)\n",
    "                elif _ == '_R3':\n",
    "                    if R3_dict[now_seq[atts_num[0]-1]] == 'H':\n",
    "                        tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                    elif R3_dict[now_seq[atts_num[0]-1]] == 'OH':\n",
    "                        tmp = tmp.replace('[*]', '[H]', 1)\n",
    "            cxsmiles[-1] = tmp\n",
    "\n",
    "            combined = utils_function.combine_cxsmiles(cxsmiles, now_seq[:atts_num[0]], R3_dict)\n",
    "            now_substructure.append(combined)\n",
    "            now_substructure += [symbol_to_smiles[_] for _ in now_seq[atts_num[0]:]]\n",
    "\n",
    "    substructure_num.append(len(now_substructure))\n",
    "    if len(now_substructure) < data_args['monomer_max_len']:\n",
    "        now_substructure += [''] * (data_args['monomer_max_len'] - len(now_substructure))\n",
    "    substructure_list.append(now_substructure)\n",
    "\n",
    "# check\n",
    "df_peptide['Monomer_Length_in_Main_Chain'].to_list() == substructure_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save substructure table\n",
    "if not os.path.exists(data_args['substructures_table_path']):\n",
    "    pd.concat([df_peptide[['CycPeptMPDB_ID', 'Source', 'Year', 'Original_Name_in_Source_Literature', \\\n",
    "                           'Structurally_Unique_ID', 'Same_Peptides_ID', 'SMILES', 'HELM', \\\n",
    "                           'Monomer_Length', 'Monomer_Length_in_Main_Chain', 'Molecule_Shape', 'Permeability', \\\n",
    "                           'PAMPA', 'Caco2', 'MDCK', 'RRCK']],\n",
    "               pd.DataFrame(substructure_list, columns=[f'Substructure-{i}' for i in range(1, data_args['monomer_max_len']+1)])], axis=1).to_csv(data_args['substructures_table_path'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
