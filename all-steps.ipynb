{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "\n",
    "from utils import utils_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.utils_function' from 'c:\\\\Users\\\\yoooo\\\\OneDrive\\\\桌面\\\\cycpeptmp\\\\utils\\\\utils_function.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "data_args = config['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Divide peptide into monomers (substructures)\n",
    "+  Divides __peptide bonds__ and __ester bonds__ (__disulfide bonds__ are not included in CycPeptMPDB data) in the main chain and splits them into monomers.\n",
    "+ __Side-chain bonds__ were not subject to division to fully represent the side-chain properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peptide = pd.read_csv(data_args['org_peptide_path'], low_memory=False)\n",
    "df_monomer = pd.read_csv(data_args['org_monomer_path'], low_memory=False)\n",
    "\n",
    "smiles = df_peptide['SMILES'].tolist()\n",
    "shape = df_peptide['Molecule_Shape'].to_list()\n",
    "helm = df_peptide['HELM'].to_list()\n",
    "symbol_to_smiles = dict(zip(df_monomer['Symbol'], df_monomer['capped_SMILES']))\n",
    "symbol_to_cxsmiles = dict(zip(df_monomer['Symbol'], df_monomer['CXSMILES']))\n",
    "R3_dict = dict(zip(df_monomer['Symbol'], df_monomer['R3']))\n",
    "smiles_to_symbol = dict(zip(df_monomer['capped_SMILES'], df_monomer['Symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "substructure_list, substructure_num = [], []\n",
    "\n",
    "for i in range(len(df_peptide)):\n",
    "\n",
    "    now_substructure = []\n",
    "    now_seq = helm[i].split('$')[0].split('{')[1].replace('}', '').replace('[', '').replace(']', '').split('.')\n",
    "\n",
    "    if shape[i] == 'Circle':\n",
    "        now_substructure = [symbol_to_smiles[_] for _ in now_seq]\n",
    "    elif shape[i] == 'Lariat':\n",
    "        # NOTE: Lariat, do not divide bonds of side chain\n",
    "        atts = helm[i].split('$')[1].split(',')[2].split('-')\n",
    "        atts_num = [int(_.split(':')[0]) for _ in atts]\n",
    "        atts_R = [_.split(':')[1] for _ in atts]\n",
    "\n",
    "        # PEPTIDE48{A.A.L.[meV].L.F.F.P.I.T.G.D.[-pip]}$PEPTIDE48,PEPTIDE48,1:R1-12:R3$$$\n",
    "        if atts_num[0] == 1:\n",
    "            # NOTE: This case were all R1-R3\n",
    "            # if atts_R[0] != 'R1':\n",
    "            #     print(f'{i}, 0, {atts_R[0]}')\n",
    "            # elif atts_R[1] != 'R3':\n",
    "            #     print(f'{i}, 1, {atts_R[1]}')\n",
    "\n",
    "            now_substructure = [symbol_to_smiles[_] for _ in now_seq[:atts_num[1]-1]]\n",
    "            # monomers to combine\n",
    "            cxsmiles = [symbol_to_cxsmiles[_] for _ in now_seq[atts_num[1]-1:]]\n",
    "            # NOTE: 第一个cap两处(R1, R3), side chain不cap\n",
    "            tmp = cxsmiles[0].split(' |')[0]\n",
    "            for _ in re.findall('_R\\d', cxsmiles[0]):\n",
    "                if _ == '_R1':\n",
    "                    tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                elif _ == '_R2':\n",
    "                    tmp = tmp.replace('[*]', '[2C]', 1)\n",
    "                elif _ == '_R3':\n",
    "                    if R3_dict[now_seq[atts_num[1]-1]] == 'H':\n",
    "                        tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                    elif R3_dict[now_seq[atts_num[1]-1]] == 'OH':\n",
    "                        tmp = tmp.replace('[*]', '[H]', 1)\n",
    "            cxsmiles[0] = tmp\n",
    "\n",
    "            combined = utils_function.combine_cxsmiles(cxsmiles, now_seq[atts_num[1]-1:], R3_dict)\n",
    "            now_substructure.append(combined)\n",
    "\n",
    "        # PEPTIDE959{[Mono22-].G.T.[Mono23].[Mono24].[dLeu(3R-OH)].[dSer(Me)].G.A.[meT].[dTyr(bR-OMe)].[Mono25]}$PEPTIDE959,PEPTIDE959,6:R3-12:R2$$$\n",
    "        else:\n",
    "            # NOTE: This case were all R3-R2\n",
    "            # if atts_R[0] != 'R3':\n",
    "            #     print(f'{i}, 0, {atts_R[0]}')\n",
    "            # elif atts_R[1] != 'R2':\n",
    "            #     print(f'{i}, 1, {atts_R[1]}')\n",
    "            cxsmiles = [symbol_to_cxsmiles[_] for _ in now_seq[:atts_num[0]]]\n",
    "            # NOTE: 最后一个cap两处(R2, R3), side chain不cap\n",
    "            tmp = cxsmiles[-1].split(' |')[0]\n",
    "            for _ in re.findall('_R\\d', cxsmiles[-1]):\n",
    "                if _ == '_R1':\n",
    "                    tmp = tmp.replace('[*]', '[1C]', 1)\n",
    "                elif _ == '_R2':\n",
    "                    tmp = tmp.replace('[*]', '[H]', 1)\n",
    "                elif _ == '_R3':\n",
    "                    if R3_dict[now_seq[atts_num[0]-1]] == 'H':\n",
    "                        tmp = tmp.replace('[*]', '[CH3]', 1)\n",
    "                    elif R3_dict[now_seq[atts_num[0]-1]] == 'OH':\n",
    "                        tmp = tmp.replace('[*]', '[H]', 1)\n",
    "            cxsmiles[-1] = tmp\n",
    "\n",
    "            combined = utils_function.combine_cxsmiles(cxsmiles, now_seq[:atts_num[0]], R3_dict)\n",
    "            now_substructure.append(combined)\n",
    "            now_substructure += [symbol_to_smiles[_] for _ in now_seq[atts_num[0]:]]\n",
    "\n",
    "    substructure_num.append(len(now_substructure))\n",
    "    if len(now_substructure) < data_args['monomer_max_len']:\n",
    "        now_substructure += [''] * (data_args['monomer_max_len'] - len(now_substructure))\n",
    "    substructure_list.append(now_substructure)\n",
    "\n",
    "# check\n",
    "df_peptide['Monomer_Length_in_Main_Chain'].to_list() == substructure_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save substructure table\n",
    "if not os.path.exists(data_args['substructures_table_path']):\n",
    "    pd.concat([df_peptide[['CycPeptMPDB_ID', 'Source', 'Year', 'Original_Name_in_Source_Literature', \\\n",
    "                        'Structurally_Unique_ID', 'Same_Peptides_ID', 'SMILES', 'HELM', \\\n",
    "                            'Monomer_Length', 'Monomer_Length_in_Main_Chain', 'Molecule_Shape', 'Permeability', \\\n",
    "                            'PAMPA', 'Caco2', 'MDCK', 'RRCK']],\n",
    "        pd.DataFrame(substructure_list, columns=[f'Substructure-{i}' for i in range(1, data_args['monomer_max_len']+1)])], axis=1).to_csv(data_args['substructures_table_path'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique substructures for descriptor calculation\n",
    "\n",
    "if not os.path.exists(data_args['unique_substructures_path']):\n",
    "    unique_substructure = list(set(sum(substructure_list, [])))[1:]\n",
    "    unique_substructure_mw = [Chem.rdMolDescriptors._CalcMolWt(Chem.MolFromSmiles(_)) for _ in unique_substructure]\n",
    "    df_substructure =  pd.DataFrame([unique_substructure, unique_substructure_mw], index=['SMILES', 'MolWt']).T\n",
    "    df_substructure = df_substructure.sort_values('MolWt').reset_index(drop=True)\n",
    "\n",
    "    tmp = []\n",
    "    i = 1\n",
    "    for _ in df_substructure['SMILES'].to_list():\n",
    "        if _ in smiles_to_symbol:\n",
    "            tmp.append(smiles_to_symbol[_])\n",
    "        else:\n",
    "            tmp.append(f'Sub{i}')\n",
    "            i += 1\n",
    "    df_substructure.insert(0, 'Symbol', tmp)\n",
    "    df_substructure.insert(0, 'ID', [i+1 for i in range(len(df_substructure))])\n",
    "    df_substructure.to_csv(data_args['unique_substructures_path'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MolWt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>CNCC=O</td>\n",
       "      <td>73.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dA</td>\n",
       "      <td>CN[C@H](C)C=O</td>\n",
       "      <td>87.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>CN[C@@H](C)C=O</td>\n",
       "      <td>87.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sar</td>\n",
       "      <td>CN(C)CC=O</td>\n",
       "      <td>87.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bal</td>\n",
       "      <td>CNCCC=O</td>\n",
       "      <td>87.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>Sub87</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)N(C)C(=O)[C...</td>\n",
       "      <td>828.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>384</td>\n",
       "      <td>Sub88</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1cccc(Cl)c1)N(C)...</td>\n",
       "      <td>832.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>385</td>\n",
       "      <td>Sub89</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...</td>\n",
       "      <td>850.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>Sub90</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H]...</td>\n",
       "      <td>860.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>Sub91</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...</td>\n",
       "      <td>864.529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Symbol                                             SMILES    MolWt\n",
       "0      1      G                                             CNCC=O   73.095\n",
       "1      2     dA                                      CN[C@H](C)C=O   87.122\n",
       "2      3      A                                     CN[C@@H](C)C=O   87.122\n",
       "3      4    Sar                                          CN(C)CC=O   87.122\n",
       "4      5    Bal                                            CNCCC=O   87.122\n",
       "..   ...    ...                                                ...      ...\n",
       "382  383  Sub87  CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)N(C)C(=O)[C...  828.109\n",
       "383  384  Sub88  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1cccc(Cl)c1)N(C)...  832.528\n",
       "384  385  Sub89  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...  850.502\n",
       "385  386  Sub90  CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H]...  860.582\n",
       "386  387  Sub91  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)N(C)C(=O...  864.529\n",
       "\n",
       "[387 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_substructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate 60 3D conformations per peptides/monomers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For peptides, different SMILES representations are first generated by __SMILES enumeration__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "data_args = config['data']\n",
    "aug_args = config['augmentation']\n",
    "\n",
    "REPLICA_NUM = aug_args['replica_num']\n",
    "\n",
    "df_peptide = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:41<00:00,  9.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import utils_function\n",
    "from utils import SmilesEnumerator\n",
    "\n",
    "sme = SmilesEnumerator.SmilesEnumerator()\n",
    "\n",
    "id = df_peptide['ID'].tolist()\n",
    "smiles = df_peptide['SMILES'].tolist()\n",
    "# canonical smiles\n",
    "smiles = [utils_function.canonicalize_smiles(_) for _ in smiles]\n",
    "label = df_peptide[data_args['target_name']].tolist()\n",
    "\n",
    "enu_id = [_ for _  in id for i in range(REPLICA_NUM)]\n",
    "enu_label = [_ for _  in label for i in range(REPLICA_NUM)]\n",
    "enu_smi = []\n",
    "\n",
    "for i in tqdm(range(len(df_peptide))):\n",
    "    for j in range(REPLICA_NUM):\n",
    "        if j == 0:\n",
    "            enu_smi.append(smiles[i])\n",
    "        else:\n",
    "            now_smi = sme.randomize_smiles(smiles[i])\n",
    "            count = 0\n",
    "            # NOTE If a new SMILES is not generated after 1000 times, save the duplicated one.\n",
    "            while now_smi in enu_smi:\n",
    "                if count >= aug_args['sme_dup_thresh']:\n",
    "                    break\n",
    "                now_smi = sme.randomize_smiles(smiles[i])\n",
    "                count += 1\n",
    "            enu_smi.append(now_smi)\n",
    "\n",
    "df_enu = pd.DataFrame([enu_id, enu_smi, enu_label], index=['ID', 'SMILES', 'y']).T\n",
    "if not os.path.exists('input/enumerated_smiles.csv'):\n",
    "    df_enu.to_csv('input/enumerated_smiles.csv', index=False)\n",
    "else:\n",
    "    print('enumerated_smiles.csv already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformation generation using RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING sdfは公開しない?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import confgene\n",
    "# config_path = 'config/PPB.json'\n",
    "# config = json.load(open(config_path,'r'))\n",
    "\n",
    "# mol_type = 'peptide'\n",
    "# sub_file_num = config['conformation']['sub_file_num']\n",
    "\n",
    "# df_enu = pd.read_csv('input/enumerated_smiles.csv', low_memory=False)\n",
    "\n",
    "# Split into multiple files for parallel computation.\n",
    "# sub_file_len = len(df_enu) // sub_file_num\n",
    "# for i in range(sub_file_num):\n",
    "#     df_enu.iloc[i*sub_file_len:(i+1)*sub_file_len].to_csv(f'sdf/{mol_type}_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2280/2280 [2:19:05<00:00,  3.66s/it]  \n",
      "100%|██████████| 2280/2280 [2:10:19<00:00,  3.43s/it]  \n",
      "100%|██████████| 2280/2280 [26:35<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run conformation generation confgene.py in parallel by yourself.\n",
    "\n",
    "# for sub in range(sub_file_num):\n",
    "    # df_exp = pd.read_csv(f'sdf/{mol_type}_{sub}.csv', low_memory=False)\n",
    "    # confgene.peptide_conformation_genetation(config, df_exp, mol_type, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check conformation nubmer\n",
    "# from rdkit import Chem\n",
    "\n",
    "# for sub in range(sub_file_num):\n",
    "#     with open(f'sdf/{mol_type}_{sub}.sdf', 'rb') as f:\n",
    "#         fsuppl = Chem.ForwardSDMolSupplier(f, removeHs=True)\n",
    "#         mols = [mol for mol in fsuppl if mol is not None]\n",
    "#         del fsuppl\n",
    "#     f.close()\n",
    "#     if sub != sub_file_num-1:\n",
    "#         if len(mols) != sub_file_len:\n",
    "#             print(sub, len(mols))\n",
    "#     else:\n",
    "#         if len(mols) != len(df_enu) - sub_file_len*(sub_file_num-1):\n",
    "#             print(sub, len(mols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### monomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [03:18<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# from utils import confgene\n",
    "# config_path = 'config/PPB.json'\n",
    "# config = json.load(open(config_path,'r'))\n",
    "\n",
    "# mol_type = 'monomer'\n",
    "\n",
    "# df = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)\n",
    "\n",
    "# confgene.monomer_conformation_genetation(config, df, mol_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate 2D and 3D descriptors for peptides and monomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils_function\n",
    "\n",
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "sub_file_num = config['conformation']['sub_file_num']\n",
    "\n",
    "df_peptide = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)\n",
    "df_monomer = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDKit (208 types 2D descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:07<00:00,  5.67it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_rdkit_descriptors(df_peptide['SMILES'].tolist(), 'peptide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 146.53it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_rdkit_descriptors(df_monomer['SMILES'].tolist(), 'monomer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mordred (1275 types 2D descriptors + 51 types 3D descriptors)\n",
    "+ Some descriptors cannot be computed when using NumPy 1.20 or later versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:32<00:00, 11.64it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_2Ddescriptors(df_peptide['SMILES'].tolist(), 'peptide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:01<00:00, 104.93it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_2Ddescriptors(df_monomer['SMILES'].tolist(), 'monomer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:17<00:00, 430.79it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_3Ddescriptors('monomer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2280/2280 [00:56<00:00, 40.31it/s]\n",
      "100%|██████████| 2280/2280 [00:52<00:00, 43.35it/s]\n",
      "100%|██████████| 2280/2280 [00:30<00:00, 74.75it/s]\n",
      "100%|██████████| 2280/2280 [00:56<00:00, 40.11it/s]\n",
      "100%|██████████| 2280/2280 [00:46<00:00, 48.82it/s]\n",
      "100%|██████████| 2280/2280 [00:36<00:00, 61.90it/s]\n",
      "100%|██████████| 2280/2280 [00:44<00:00, 50.96it/s]\n",
      "100%|██████████| 2280/2280 [00:35<00:00, 64.97it/s]\n",
      "100%|██████████| 2280/2280 [01:03<00:00, 36.06it/s]\n",
      "100%|██████████| 2280/2280 [00:37<00:00, 61.25it/s] \n"
     ]
    }
   ],
   "source": [
    "for sub in range(sub_file_num):\n",
    "    utils_function.calc_mordred_3Ddescriptors('peptide', sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOE (206 types 2D descriptors + 117 types 3D descriptors)\n",
    "+ CycPeptMP used the commercial software __MOE__ to calculate some of the descriptors. In particular, many of the selected 3D descriptors were computed by __MOE__.\n",
    "+ Please manualy calculate these descriptors. I showed __MOE_3D_descriptors.sh__ as an example.\n",
    "+ For 2D descriptors:\n",
    "    + Please wash SMILES and use washed mols for calculation.\n",
    "        + for GUI: Molecule -> Wash -> Protonation: Dominant\n",
    "+ For 3D descriptors:\n",
    "    + First, please calculate the charge against the RDKit conformation.\n",
    "        + for GUI: Compute -> Molecule -> Partial Charges\n",
    "    + 21 MOPAC descriptors of the 3D descriptors were not computed due to computational cost (AM_x, MNDO_x, PM3_x)\n",
    "+ If you cannot compute them, please exclude the MOE part from the after procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mol_type in ['peptide', 'monomer']:\n",
    "    df_moe = pd.read_csv(f'desc/{mol_type}_moe_2D.csv')\n",
    "    df = df_moe.iloc[:, :df_moe.columns.to_list().index('apol')].copy()\n",
    "    df_moe = df_moe.iloc[:, df_moe.columns.to_list().index('apol'):].select_dtypes('number')\n",
    "\n",
    "    df_rdkit = pd.read_csv(f'desc/{mol_type}_rdkit.csv').select_dtypes('number')\n",
    "    name_dup = []\n",
    "    for _ in df_rdkit.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_rdkit' for _ in name_dup]))\n",
    "    df_rdkit = df_rdkit.rename(columns=name_dup)\n",
    "\n",
    "    df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_2D.csv').select_dtypes('number')\n",
    "    name_dup = []\n",
    "    for _ in df_mordred.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_mordred' for _ in name_dup]))\n",
    "    df_mordred = df_mordred.rename(columns=name_dup)\n",
    "\n",
    "    df = pd.concat([df, df_moe, df_rdkit, df_mordred], axis=1)\n",
    "    df.to_csv(f'input/{mol_type}_2D.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "\n",
    "for mol_type in ['peptide', 'monomer']:\n",
    "    if mol_type == 'peptide':\n",
    "        for sub in range(config['conformation']['sub_file_num']):\n",
    "            if sub == 0:\n",
    "                df_moe = pd.read_csv(f'desc/{mol_type}_moe_3D_{sub}.csv')\n",
    "                df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_3D_{sub}.csv')\n",
    "            else:\n",
    "                df_moe = pd.concat([df_moe, pd.read_csv(f'desc/{mol_type}_moe_3D_{sub}.csv')], axis=0)\n",
    "                df_mordred = pd.concat([df_mordred, pd.read_csv(f'desc/{mol_type}_mordred_3D_{sub}.csv')], axis=0)\n",
    "        df_moe = df_moe.reset_index(drop=True)\n",
    "        df_mordred = df_mordred.reset_index(drop=True)\n",
    "    elif mol_type == 'monomer':\n",
    "        df_moe = pd.read_csv(f'desc/{mol_type}_moe_3D.csv')\n",
    "        df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_3D.csv')\n",
    "\n",
    "    df = df_moe.iloc[:, :df_moe.columns.to_list().index('ASA')].copy()\n",
    "    df_moe = df_moe.iloc[:, df_moe.columns.to_list().index('ASA'):].select_dtypes('number')\n",
    "\n",
    "    name_dup = []\n",
    "    for _ in df_mordred.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_mordred' for _ in name_dup]))\n",
    "    df_mordred = df_mordred.rename(columns=name_dup).select_dtypes('number')\n",
    "\n",
    "    if mol_type == 'peptide':\n",
    "        df_enu = pd.read_csv('input/enumerated_smiles.csv', low_memory=False)\n",
    "        df = pd.concat([df_enu, df, df_moe, df_mordred], axis=1)\n",
    "    elif mol_type == 'monomer':\n",
    "        df_monomer = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)\n",
    "        df_monomer = df_monomer.iloc[df_monomer.index.repeat(config['augmentation']['replica_num'])].reset_index(drop=True)\n",
    "        df = pd.concat([df_monomer, df, df_moe, df_mordred], axis=1)\n",
    "\n",
    "    df.to_csv(f'input/{mol_type}_3D.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Select only PAMPA entries of CycPeptMPDB and remove duplicate structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING ここで重複をなし、目的変数の上限下限を丸める\n",
    "\n",
    "data_args = config['data']\n",
    "\n",
    "# All data from CycPeptMPDB\n",
    "df = pd.read_csv(data_args['org_data_path'], low_memory=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "valid_args = config['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splie Test set by Kennard–Stone algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZE\n",
    "\n",
    "df = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)\n",
    "\n",
    "test_index = [0, 1, 19, 24, 33, 34, 41, 42, 44, 52, 55, 58, 71, 77, 107, 109, 135, 168, 186, 194, 211, 218, 259, 273, 284, 306, 310, 311, 312, 314, 316, 319, 343, 350, 357, 358, 361]\n",
    "np.save('data/validation/Test_index.npy', test_index)\n",
    "drugbank_index = [_ for _ in range(363, 380)]\n",
    "np.save('data/validation/DrugBank_index.npy', drugbank_index)\n",
    "\n",
    "test_ids = [_+1 for _ in test_index]\n",
    "np.save('data/validation/Test_ids.npy', test_ids)\n",
    "drugbank_ids = [_+1 for _ in drugbank_index]\n",
    "np.save('data/validation/DrugBank_ids.npy', drugbank_ids)\n",
    "\n",
    "train_valid_index = df.drop(test_index+drugbank_index).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split validation sets from the rest so that there is no duplication between validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_ids = df.iloc[train_valid_index]['ID'].to_list()\n",
    "\n",
    "for cv, cv_seed in zip(range(valid_args['cv']), valid_args['cv_seed']):\n",
    "    random.seed(cv_seed)\n",
    "    if cv == 0:\n",
    "        tmp_ids = train_valid_ids\n",
    "\n",
    "    valid_ids = sorted(random.sample(tmp_ids, len(test_ids)))\n",
    "    train_ids = sorted(list(set(train_valid_ids) - set(valid_ids)))\n",
    "    np.save(f'data/validation/Train_ids_cv{cv}.npy', train_ids)\n",
    "    np.save(f'data/validation/Valid_ids_cv{cv}.npy', valid_ids)\n",
    "\n",
    "    valid_index = df[df['ID'].isin(valid_ids)].index.to_list()\n",
    "    train_index = df[df['ID'].isin(train_ids)].index.to_list()\n",
    "    np.save(f'data/validation/Train_index_cv{cv}.npy', train_index)\n",
    "    np.save(f'data/validation/Valid_index_cv{cv}.npy', valid_index)\n",
    "\n",
    "    # update tmp_ids\n",
    "    tmp_ids = sorted(list(set(tmp_ids) - set(valid_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptors selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils_function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/peptide_2D.csv', low_memory=False)\n",
    "# OPTIMIZE target_name\n",
    "label_list = df[config['data']['target_name']].to_numpy()\n",
    "smiles_list = df['SMILES'].to_numpy()\n",
    "df_2D = df.iloc[:, df.columns.to_list().index('apol'):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deleted by standard deviation: 307\n",
    "# # Deleted by similarity: 1048\n",
    "# # Feature map shape: (380, 335)\n",
    "\n",
    "# features_delete_std, features_delete_std_R, data_preprocessed = \\\n",
    "#   utils_function.entire_preprocessing(df_2D, label_list, threshold=config['feature_selection']['similarity_thresh'])\n",
    "# np.savez_compressed('input/peptide_selected_2D.npz',\n",
    "#                     features_delete_std=features_delete_std,\n",
    "#                     features_delete_std_R=features_delete_std_R,\n",
    "#                     features_use=data_preprocessed.columns.to_list(),\n",
    "#                     data_preprocessed=data_preprocessed.values)\n",
    "\n",
    "load = np.load('input/peptide_selected_2D.npz')\n",
    "data_preprocessed_2D = pd.DataFrame(load['data_preprocessed'], columns=load['features_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by RF for 3-cv\n",
    "importances = []\n",
    "for cv in range(config['validation']['cv']):\n",
    "    indices = np.load(f'data/validation/Train_index_cv{cv}.npy')\n",
    "    x = data_preprocessed_2D.iloc[indices]\n",
    "    y = label_list[indices]\n",
    "    RF = RandomForestRegressor(n_estimators=500, random_state=233, n_jobs=12)\n",
    "    RF.fit(x, y)\n",
    "    importances.append(RF.feature_importances_)\n",
    "\n",
    "importances = np.array(importances).mean(axis=0)\n",
    "\n",
    "df_tmp = pd.DataFrame(importances, index=x.columns, columns=['importances']).sort_values('importances', ascending=False)[:15].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logP(o/w)</td>\n",
       "      <td>0.302166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEOE_VSA-1</td>\n",
       "      <td>0.140975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMID_h</td>\n",
       "      <td>0.028466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AATSC0c</td>\n",
       "      <td>0.027915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIC1</td>\n",
       "      <td>0.027676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AATS4se</td>\n",
       "      <td>0.018925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MinEStateIndex</td>\n",
       "      <td>0.018824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MolLogP</td>\n",
       "      <td>0.018142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IC0</td>\n",
       "      <td>0.016368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.013720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AATSC3c</td>\n",
       "      <td>0.013463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATSC8dv</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GATS3p</td>\n",
       "      <td>0.013291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h_logD</td>\n",
       "      <td>0.013220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>logS</td>\n",
       "      <td>0.011550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  importances\n",
       "0        logP(o/w)     0.302166\n",
       "1       PEOE_VSA-1     0.140975\n",
       "2           AMID_h     0.028466\n",
       "3          AATSC0c     0.027915\n",
       "4             BIC1     0.027676\n",
       "5          AATS4se     0.018925\n",
       "6   MinEStateIndex     0.018824\n",
       "7          MolLogP     0.018142\n",
       "8              IC0     0.016368\n",
       "9      VSA_EState3     0.013720\n",
       "10         AATSC3c     0.013463\n",
       "11         ATSC8dv     0.013436\n",
       "12          GATS3p     0.013291\n",
       "13          h_logD     0.013220\n",
       "14            logS     0.011550"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_2D = ['logP(o/w)', 'PEOE_VSA-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 174)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3D = pd.read_csv('input/peptide_3D.csv', low_memory=False)\n",
    "# Use the top conformation for selection\n",
    "df_3D = df_3D.iloc[[config['augmentation']['replica_num']*_ for _ in range(len(df))]].reset_index(drop=True)\n",
    "df\n",
    "df_3D.shape\n",
    "# (7337, 175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deleted by standard deviation: 1\n",
    "# # Deleted by similarity: 115\n",
    "# # Feature map shape: (380, 52)\n",
    "\n",
    "# features_delete_std, features_delete_std_R, data_preprocessed = \\\n",
    "#     utils_function.entire_preprocessing(df_3D.iloc[:, df_3D.columns.to_list().index('ASA'):].copy(), label_list, threshold=config['feature_selection']['similarity_thresh'])\n",
    "# np.savez_compressed('input/peptide_selected_3D.npz',\n",
    "#                     features_delete_std=features_delete_std,\n",
    "#                     features_delete_std_R=features_delete_std_R,\n",
    "#                     features_use=data_preprocessed.columns.to_list(),\n",
    "#                     data_preprocessed=data_preprocessed.values)\n",
    "\n",
    "load = np.load('input/peptide_selected_3D.npz')\n",
    "data_preprocessed_3D = pd.DataFrame(load['data_preprocessed'], columns=load['features_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by RF for 3-cv\n",
    "importances = []\n",
    "for cv in range(config['validation']['cv']):\n",
    "    indices = np.load(f'data/validation/Train_index_cv{cv}.npy')\n",
    "    x = data_preprocessed_3D.iloc[indices]\n",
    "    y = label_list[indices]\n",
    "    RF = RandomForestRegressor(n_estimators=500, random_state=233, n_jobs=12)\n",
    "    RF.fit(x, y)\n",
    "    importances.append(RF.feature_importances_)\n",
    "\n",
    "importances = np.array(importances).mean(axis=0)\n",
    "\n",
    "df_tmp = pd.DataFrame(importances, index=x.columns, columns=['importances']).sort_values('importances', ascending=False)[:15].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vsurf_CW1</td>\n",
       "      <td>0.170764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vsurf_CW3</td>\n",
       "      <td>0.160359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vsurf_CW2</td>\n",
       "      <td>0.096998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPSA</td>\n",
       "      <td>0.058411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vsurf_D5</td>\n",
       "      <td>0.053362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vsurf_HL1</td>\n",
       "      <td>0.052220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vsurf_IW8</td>\n",
       "      <td>0.030033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TASA</td>\n",
       "      <td>0.026045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E_vdw</td>\n",
       "      <td>0.021730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FASA_P</td>\n",
       "      <td>0.020075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E_ele</td>\n",
       "      <td>0.019308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dens</td>\n",
       "      <td>0.018835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PNSA1</td>\n",
       "      <td>0.018138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vsurf_HB8</td>\n",
       "      <td>0.016136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vsurf_IW1</td>\n",
       "      <td>0.014757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  importances\n",
       "0   vsurf_CW1     0.170764\n",
       "1   vsurf_CW3     0.160359\n",
       "2   vsurf_CW2     0.096998\n",
       "3        RPSA     0.058411\n",
       "4    vsurf_D5     0.053362\n",
       "5   vsurf_HL1     0.052220\n",
       "6   vsurf_IW8     0.030033\n",
       "7        TASA     0.026045\n",
       "8       E_vdw     0.021730\n",
       "9      FASA_P     0.020075\n",
       "10      E_ele     0.019308\n",
       "11       dens     0.018835\n",
       "12      PNSA1     0.018138\n",
       "13  vsurf_HB8     0.016136\n",
       "14  vsurf_IW1     0.014757"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_3D = ['vsurf_CW1', 'vsurf_CW3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model input generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "folder_path = f'Atom'\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
