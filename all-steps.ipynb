{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.utils_function' from 'd:\\\\mp_ppb\\\\utils\\\\utils_function.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Select only PAMPA entries of CycPeptMPDB and remove duplicate structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING ここで重複をなし、目的変数の上限下限を丸める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Divide peptide into monomers\n",
    "+  Divides __peptide bonds__, __ester bonds__, and (not in CycPeptMPDB data) __disulfide bonds__ in the main chain and splits them into monomers (side chain bonds are not divided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "data_args = config['data']\n",
    "\n",
    "df_peptide = pd.read_csv(data_args['peptide_path'], low_memory=False)\n",
    "smiles = df_peptide[data_args['mol_name']].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.divide_monomer' from '/Users/yoshio/Desktop/cycpeptmp_PPB/utils/divide_monomer.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import divide_monomer\n",
    "\n",
    "import importlib\n",
    "importlib.reload(divide_monomer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:26<00:00, 14.21it/s]\n"
     ]
    }
   ],
   "source": [
    "monomers = []\n",
    "for smi in tqdm(smiles):\n",
    "    monomers.append(divide_monomer.cut_cyclic_peptide_to_monomers(smi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomers_cut = list(set(sum(monomers,[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monomer = pd.read_csv('data/substructure_descriptor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN(C)[C@@H](CSCC=O)C(=O)NCC(N)=O\n",
      "CN[C@@H](CS)C(=O)N[C@H](C(N)=O)[C@@H](C)O\n",
      "CN[C@@H](CSCC=O)C(=O)NCC(N)=O\n",
      "CN[C@@H](CSCC=O)C(=O)NCC(=O)NCC(N)=O\n"
     ]
    }
   ],
   "source": [
    "for _ in monomers_cut:\n",
    "    if _ not in df_monomer['mol'].tolist():\n",
    "        print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN[C@H](C=O)CS\n",
      "CNC(CSCC=O)C(=O)NCC(N)=O\n",
      "CN(C)C(CSCC=O)C(=O)NCC(N)=O\n",
      "CNC(CSCC=O)C(=O)NCC(=O)NCC(N)=O\n"
     ]
    }
   ],
   "source": [
    "for _ in df_monomer['mol'].tolist():\n",
    "    if _ not in monomers_cut:\n",
    "        print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING save monomer_list and pep_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate 60 3D conformations per peptides/monomers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For peptides, different SMILES representations are first generated by __SMILES enumeration__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "data_args = config['data']\n",
    "aug_args = config['augmentation']\n",
    "\n",
    "REPLICA_NUM = aug_args['replica_num']\n",
    "\n",
    "df_peptide = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:41<00:00,  9.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import utils_function\n",
    "from utils import SmilesEnumerator\n",
    "\n",
    "sme = SmilesEnumerator.SmilesEnumerator()\n",
    "\n",
    "id = df_peptide['ID'].tolist()\n",
    "smiles = df_peptide['SMILES'].tolist()\n",
    "# canonical smiles\n",
    "smiles = [utils_function.canonicalize_smiles(_) for _ in smiles]\n",
    "label = df_peptide[data_args['target_name']].tolist()\n",
    "\n",
    "enu_id = [_ for _  in id for i in range(REPLICA_NUM)]\n",
    "enu_label = [_ for _  in label for i in range(REPLICA_NUM)]\n",
    "enu_smi = []\n",
    "\n",
    "for i in tqdm(range(len(df_peptide))):\n",
    "    for j in range(REPLICA_NUM):\n",
    "        if j == 0:\n",
    "            enu_smi.append(smiles[i])\n",
    "        else:\n",
    "            now_smi = sme.randomize_smiles(smiles[i])\n",
    "            count = 0\n",
    "            # NOTE If a new SMILES is not generated after 1000 times, save the duplicated one.\n",
    "            while now_smi in enu_smi:\n",
    "                if count >= aug_args['sme_dup_thresh']:\n",
    "                    break\n",
    "                now_smi = sme.randomize_smiles(smiles[i])\n",
    "                count += 1\n",
    "            enu_smi.append(now_smi)\n",
    "\n",
    "df_enu = pd.DataFrame([enu_id, enu_smi, enu_label], index=['ID', 'SMILES', 'y']).T\n",
    "if not os.path.exists('input/enumerated_smiles.csv'):\n",
    "    df_enu.to_csv('input/enumerated_smiles.csv', index=False)\n",
    "else:\n",
    "    print('enumerated_smiles.csv already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformation generation using RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING sdfは公開しない?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import confgene\n",
    "# config_path = 'config/PPB.json'\n",
    "# config = json.load(open(config_path,'r'))\n",
    "\n",
    "# mol_type = 'peptide'\n",
    "# sub_file_num = config['conformation']['sub_file_num']\n",
    "\n",
    "# df_enu = pd.read_csv('input/enumerated_smiles.csv', low_memory=False)\n",
    "\n",
    "# Split into multiple files for parallel computation.\n",
    "# sub_file_len = len(df_enu) // sub_file_num\n",
    "# for i in range(sub_file_num):\n",
    "#     df_enu.iloc[i*sub_file_len:(i+1)*sub_file_len].to_csv(f'sdf/{mol_type}_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2280/2280 [2:19:05<00:00,  3.66s/it]  \n",
      "100%|██████████| 2280/2280 [2:10:19<00:00,  3.43s/it]  \n",
      "100%|██████████| 2280/2280 [26:35<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run conformation generation confgene.py in parallel by yourself.\n",
    "\n",
    "# for sub in range(sub_file_num):\n",
    "    # df_exp = pd.read_csv(f'sdf/{mol_type}_{sub}.csv', low_memory=False)\n",
    "    # confgene.peptide_conformation_genetation(config, df_exp, mol_type, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check conformation nubmer\n",
    "# from rdkit import Chem\n",
    "\n",
    "# for sub in range(sub_file_num):\n",
    "#     with open(f'sdf/{mol_type}_{sub}.sdf', 'rb') as f:\n",
    "#         fsuppl = Chem.ForwardSDMolSupplier(f, removeHs=True)\n",
    "#         mols = [mol for mol in fsuppl if mol is not None]\n",
    "#         del fsuppl\n",
    "#     f.close()\n",
    "#     if sub != sub_file_num-1:\n",
    "#         if len(mols) != sub_file_len:\n",
    "#             print(sub, len(mols))\n",
    "#     else:\n",
    "#         if len(mols) != len(df_enu) - sub_file_len*(sub_file_num-1):\n",
    "#             print(sub, len(mols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### monomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [03:18<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# from utils import confgene\n",
    "# config_path = 'config/PPB.json'\n",
    "# config = json.load(open(config_path,'r'))\n",
    "\n",
    "# mol_type = 'monomer'\n",
    "\n",
    "# df = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)\n",
    "\n",
    "# confgene.monomer_conformation_genetation(config, df, mol_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate 2D and 3D descriptors for peptides and monomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils_function\n",
    "\n",
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "sub_file_num = config['conformation']['sub_file_num']\n",
    "\n",
    "df_peptide = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)\n",
    "df_monomer = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDKit (208 types 2D descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:07<00:00,  5.67it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_rdkit_descriptors(df_peptide['SMILES'].tolist(), 'peptide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 146.53it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_rdkit_descriptors(df_monomer['SMILES'].tolist(), 'monomer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mordred (1275 types 2D descriptors + 51 types 3D descriptors)\n",
    "+ Some descriptors cannot be computed when using NumPy 1.20 or later versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:32<00:00, 11.64it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_2Ddescriptors(df_peptide['SMILES'].tolist(), 'peptide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:01<00:00, 104.93it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_2Ddescriptors(df_monomer['SMILES'].tolist(), 'monomer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:17<00:00, 430.79it/s]\n"
     ]
    }
   ],
   "source": [
    "utils_function.calc_mordred_3Ddescriptors('monomer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2280/2280 [00:56<00:00, 40.31it/s]\n",
      "100%|██████████| 2280/2280 [00:52<00:00, 43.35it/s]\n",
      "100%|██████████| 2280/2280 [00:30<00:00, 74.75it/s]\n",
      "100%|██████████| 2280/2280 [00:56<00:00, 40.11it/s]\n",
      "100%|██████████| 2280/2280 [00:46<00:00, 48.82it/s]\n",
      "100%|██████████| 2280/2280 [00:36<00:00, 61.90it/s]\n",
      "100%|██████████| 2280/2280 [00:44<00:00, 50.96it/s]\n",
      "100%|██████████| 2280/2280 [00:35<00:00, 64.97it/s]\n",
      "100%|██████████| 2280/2280 [01:03<00:00, 36.06it/s]\n",
      "100%|██████████| 2280/2280 [00:37<00:00, 61.25it/s] \n"
     ]
    }
   ],
   "source": [
    "for sub in range(sub_file_num):\n",
    "    utils_function.calc_mordred_3Ddescriptors('peptide', sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOE (206 types 2D descriptors + 117 types 3D descriptors)\n",
    "+ CycPeptMP used the commercial software __MOE__ to calculate some of the descriptors. In particular, many of the selected 3D descriptors were computed by __MOE__.\n",
    "+ Please manualy calculate these descriptors. I showed __MOE_3D_descriptors.sh__ as an example.\n",
    "+ For 2D descriptors:\n",
    "    + Please wash SMILES and use washed mols for calculation.\n",
    "        + for GUI: Molecule -> Wash -> Protonation: Dominant\n",
    "+ For 3D descriptors:\n",
    "    + First, please calculate the charge against the RDKit conformation.\n",
    "        + for GUI: Compute -> Molecule -> Partial Charges\n",
    "    + 21 MOPAC descriptors of the 3D descriptors were not computed due to computational cost (AM_x, MNDO_x, PM3_x)\n",
    "+ If you cannot compute them, please exclude the MOE part from the after procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mol_type in ['peptide', 'monomer']:\n",
    "    df_moe = pd.read_csv(f'desc/{mol_type}_moe_2D.csv')\n",
    "    df = df_moe.iloc[:, :df_moe.columns.to_list().index('apol')].copy()\n",
    "    df_moe = df_moe.iloc[:, df_moe.columns.to_list().index('apol'):].select_dtypes('number')\n",
    "\n",
    "    df_rdkit = pd.read_csv(f'desc/{mol_type}_rdkit.csv').select_dtypes('number')\n",
    "    name_dup = []\n",
    "    for _ in df_rdkit.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_rdkit' for _ in name_dup]))\n",
    "    df_rdkit = df_rdkit.rename(columns=name_dup)\n",
    "\n",
    "    df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_2D.csv').select_dtypes('number')\n",
    "    name_dup = []\n",
    "    for _ in df_mordred.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_mordred' for _ in name_dup]))\n",
    "    df_mordred = df_mordred.rename(columns=name_dup)\n",
    "\n",
    "    df = pd.concat([df, df_moe, df_rdkit, df_mordred], axis=1)\n",
    "    df.to_csv(f'input/{mol_type}_2D.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "\n",
    "for mol_type in ['peptide', 'monomer']:\n",
    "    if mol_type == 'peptide':\n",
    "        for sub in range(config['conformation']['sub_file_num']):\n",
    "            if sub == 0:\n",
    "                df_moe = pd.read_csv(f'desc/{mol_type}_moe_3D_{sub}.csv')\n",
    "                df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_3D_{sub}.csv')\n",
    "            else:\n",
    "                df_moe = pd.concat([df_moe, pd.read_csv(f'desc/{mol_type}_moe_3D_{sub}.csv')], axis=0)\n",
    "                df_mordred = pd.concat([df_mordred, pd.read_csv(f'desc/{mol_type}_mordred_3D_{sub}.csv')], axis=0)\n",
    "        df_moe = df_moe.reset_index(drop=True)\n",
    "        df_mordred = df_mordred.reset_index(drop=True)\n",
    "    elif mol_type == 'monomer':\n",
    "        df_moe = pd.read_csv(f'desc/{mol_type}_moe_3D.csv')\n",
    "        df_mordred = pd.read_csv(f'desc/{mol_type}_mordred_3D.csv')\n",
    "\n",
    "    df = df_moe.iloc[:, :df_moe.columns.to_list().index('ASA')].copy()\n",
    "    df_moe = df_moe.iloc[:, df_moe.columns.to_list().index('ASA'):].select_dtypes('number')\n",
    "\n",
    "    name_dup = []\n",
    "    for _ in df_mordred.columns:\n",
    "        if _ in df_moe.columns.to_list():\n",
    "            name_dup.append(_)\n",
    "    name_dup = dict(zip(name_dup, [_+'_mordred' for _ in name_dup]))\n",
    "    df_mordred = df_mordred.rename(columns=name_dup).select_dtypes('number')\n",
    "\n",
    "    if mol_type == 'peptide':\n",
    "        df_enu = pd.read_csv('input/enumerated_smiles.csv', low_memory=False)\n",
    "        df = pd.concat([df_enu, df, df_moe, df_mordred], axis=1)\n",
    "    elif mol_type == 'monomer':\n",
    "        df_monomer = pd.read_csv(\"data/monomer_list.csv\", low_memory=False)\n",
    "        df_monomer = df_monomer.iloc[df_monomer.index.repeat(config['augmentation']['replica_num'])].reset_index(drop=True)\n",
    "        df = pd.concat([df_monomer, df, df_moe, df_mordred], axis=1)\n",
    "\n",
    "    df.to_csv(f'input/{mol_type}_3D.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))\n",
    "valid_args = config['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splie Test set by Kennard–Stone algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZE\n",
    "\n",
    "df = pd.read_csv(\"data/pep_sequence.csv\", low_memory=False)\n",
    "\n",
    "test_index = [0, 1, 19, 24, 33, 34, 41, 42, 44, 52, 55, 58, 71, 77, 107, 109, 135, 168, 186, 194, 211, 218, 259, 273, 284, 306, 310, 311, 312, 314, 316, 319, 343, 350, 357, 358, 361]\n",
    "np.save('data/validation/Test_index.npy', test_index)\n",
    "drugbank_index = [_ for _ in range(363, 380)]\n",
    "np.save('data/validation/DrugBank_index.npy', drugbank_index)\n",
    "\n",
    "test_ids = [_+1 for _ in test_index]\n",
    "np.save('data/validation/Test_ids.npy', test_ids)\n",
    "drugbank_ids = [_+1 for _ in drugbank_index]\n",
    "np.save('data/validation/DrugBank_ids.npy', drugbank_ids)\n",
    "\n",
    "train_valid_index = df.drop(test_index+drugbank_index).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split validation sets from the rest so that there is no duplication between validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_ids = df.iloc[train_valid_index]['ID'].to_list()\n",
    "\n",
    "for cv, cv_seed in zip(range(valid_args['cv']), valid_args['cv_seed']):\n",
    "    random.seed(cv_seed)\n",
    "    if cv == 0:\n",
    "        tmp_ids = train_valid_ids\n",
    "\n",
    "    valid_ids = sorted(random.sample(tmp_ids, len(test_ids)))\n",
    "    train_ids = sorted(list(set(train_valid_ids) - set(valid_ids)))\n",
    "    np.save(f'data/validation/Train_ids_cv{cv}.npy', train_ids)\n",
    "    np.save(f'data/validation/Valid_ids_cv{cv}.npy', valid_ids)\n",
    "\n",
    "    valid_index = df[df['ID'].isin(valid_ids)].index.to_list()\n",
    "    train_index = df[df['ID'].isin(train_ids)].index.to_list()\n",
    "    np.save(f'data/validation/Train_index_cv{cv}.npy', train_index)\n",
    "    np.save(f'data/validation/Valid_index_cv{cv}.npy', valid_index)\n",
    "\n",
    "    # update tmp_ids\n",
    "    tmp_ids = sorted(list(set(tmp_ids) - set(valid_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptors selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils_function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "config_path = 'config/PPB.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/peptide_2D.csv', low_memory=False)\n",
    "# OPTIMIZE target_name\n",
    "label_list = df[config['data']['target_name']].to_numpy()\n",
    "smiles_list = df['SMILES'].to_numpy()\n",
    "df_2D = df.iloc[:, df.columns.to_list().index('apol'):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deleted by standard deviation: 307\n",
    "# # Deleted by similarity: 1048\n",
    "# # Feature map shape: (380, 335)\n",
    "\n",
    "# features_delete_std, features_delete_std_R, data_preprocessed = \\\n",
    "#   utils_function.entire_preprocessing(df_2D, label_list, threshold=config['feature_selection']['similarity_thresh'])\n",
    "# np.savez_compressed('input/peptide_selected_2D.npz',\n",
    "#                     features_delete_std=features_delete_std,\n",
    "#                     features_delete_std_R=features_delete_std_R,\n",
    "#                     features_use=data_preprocessed.columns.to_list(),\n",
    "#                     data_preprocessed=data_preprocessed.values)\n",
    "\n",
    "load = np.load('input/peptide_selected_2D.npz')\n",
    "data_preprocessed_2D = pd.DataFrame(load['data_preprocessed'], columns=load['features_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by RF for 3-cv\n",
    "importances = []\n",
    "for cv in range(config['validation']['cv']):\n",
    "    indices = np.load(f'data/validation/Train_index_cv{cv}.npy')\n",
    "    x = data_preprocessed_2D.iloc[indices]\n",
    "    y = label_list[indices]\n",
    "    RF = RandomForestRegressor(n_estimators=500, random_state=233, n_jobs=12)\n",
    "    RF.fit(x, y)\n",
    "    importances.append(RF.feature_importances_)\n",
    "\n",
    "importances = np.array(importances).mean(axis=0)\n",
    "\n",
    "df_tmp = pd.DataFrame(importances, index=x.columns, columns=['importances']).sort_values('importances', ascending=False)[:15].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logP(o/w)</td>\n",
       "      <td>0.302166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEOE_VSA-1</td>\n",
       "      <td>0.140975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMID_h</td>\n",
       "      <td>0.028466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AATSC0c</td>\n",
       "      <td>0.027915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIC1</td>\n",
       "      <td>0.027676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AATS4se</td>\n",
       "      <td>0.018925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MinEStateIndex</td>\n",
       "      <td>0.018824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MolLogP</td>\n",
       "      <td>0.018142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IC0</td>\n",
       "      <td>0.016368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.013720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AATSC3c</td>\n",
       "      <td>0.013463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATSC8dv</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GATS3p</td>\n",
       "      <td>0.013291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h_logD</td>\n",
       "      <td>0.013220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>logS</td>\n",
       "      <td>0.011550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  importances\n",
       "0        logP(o/w)     0.302166\n",
       "1       PEOE_VSA-1     0.140975\n",
       "2           AMID_h     0.028466\n",
       "3          AATSC0c     0.027915\n",
       "4             BIC1     0.027676\n",
       "5          AATS4se     0.018925\n",
       "6   MinEStateIndex     0.018824\n",
       "7          MolLogP     0.018142\n",
       "8              IC0     0.016368\n",
       "9      VSA_EState3     0.013720\n",
       "10         AATSC3c     0.013463\n",
       "11         ATSC8dv     0.013436\n",
       "12          GATS3p     0.013291\n",
       "13          h_logD     0.013220\n",
       "14            logS     0.011550"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_2D = ['logP(o/w)', 'PEOE_VSA-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 174)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3D = pd.read_csv('input/peptide_3D.csv', low_memory=False)\n",
    "# Use the top conformation for selection\n",
    "df_3D = df_3D.iloc[[config['augmentation']['replica_num']*_ for _ in range(len(df))]].reset_index(drop=True)\n",
    "df\n",
    "df_3D.shape\n",
    "# (7337, 175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deleted by standard deviation: 1\n",
    "# # Deleted by similarity: 115\n",
    "# # Feature map shape: (380, 52)\n",
    "\n",
    "# features_delete_std, features_delete_std_R, data_preprocessed = \\\n",
    "#     utils_function.entire_preprocessing(df_3D.iloc[:, df_3D.columns.to_list().index('ASA'):].copy(), label_list, threshold=config['feature_selection']['similarity_thresh'])\n",
    "# np.savez_compressed('input/peptide_selected_3D.npz',\n",
    "#                     features_delete_std=features_delete_std,\n",
    "#                     features_delete_std_R=features_delete_std_R,\n",
    "#                     features_use=data_preprocessed.columns.to_list(),\n",
    "#                     data_preprocessed=data_preprocessed.values)\n",
    "\n",
    "load = np.load('input/peptide_selected_3D.npz')\n",
    "data_preprocessed_3D = pd.DataFrame(load['data_preprocessed'], columns=load['features_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by RF for 3-cv\n",
    "importances = []\n",
    "for cv in range(config['validation']['cv']):\n",
    "    indices = np.load(f'data/validation/Train_index_cv{cv}.npy')\n",
    "    x = data_preprocessed_3D.iloc[indices]\n",
    "    y = label_list[indices]\n",
    "    RF = RandomForestRegressor(n_estimators=500, random_state=233, n_jobs=12)\n",
    "    RF.fit(x, y)\n",
    "    importances.append(RF.feature_importances_)\n",
    "\n",
    "importances = np.array(importances).mean(axis=0)\n",
    "\n",
    "df_tmp = pd.DataFrame(importances, index=x.columns, columns=['importances']).sort_values('importances', ascending=False)[:15].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vsurf_CW1</td>\n",
       "      <td>0.170764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vsurf_CW3</td>\n",
       "      <td>0.160359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vsurf_CW2</td>\n",
       "      <td>0.096998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPSA</td>\n",
       "      <td>0.058411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vsurf_D5</td>\n",
       "      <td>0.053362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vsurf_HL1</td>\n",
       "      <td>0.052220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vsurf_IW8</td>\n",
       "      <td>0.030033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TASA</td>\n",
       "      <td>0.026045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E_vdw</td>\n",
       "      <td>0.021730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FASA_P</td>\n",
       "      <td>0.020075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E_ele</td>\n",
       "      <td>0.019308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dens</td>\n",
       "      <td>0.018835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PNSA1</td>\n",
       "      <td>0.018138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vsurf_HB8</td>\n",
       "      <td>0.016136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vsurf_IW1</td>\n",
       "      <td>0.014757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  importances\n",
       "0   vsurf_CW1     0.170764\n",
       "1   vsurf_CW3     0.160359\n",
       "2   vsurf_CW2     0.096998\n",
       "3        RPSA     0.058411\n",
       "4    vsurf_D5     0.053362\n",
       "5   vsurf_HL1     0.052220\n",
       "6   vsurf_IW8     0.030033\n",
       "7        TASA     0.026045\n",
       "8       E_vdw     0.021730\n",
       "9      FASA_P     0.020075\n",
       "10      E_ele     0.019308\n",
       "11       dens     0.018835\n",
       "12      PNSA1     0.018138\n",
       "13  vsurf_HB8     0.016136\n",
       "14  vsurf_IW1     0.014757"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_3D = ['vsurf_CW1', 'vsurf_CW3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model input generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "folder_path = f'Atom'\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
